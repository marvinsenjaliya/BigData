{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = sc.textFile(\"file:///home/hduser/export_dataframe.csv\")\n",
    "print(textfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"file:///home/hduser/export_dataframe.csv\" , inferSchema=True , header=True)\n",
    "print(df.show())\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe('working_hour').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "df.select('username','working_hour').show()\n",
    "df.select(mean(df(\"working_hour\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_commers = df.filter(df.idle_time>=\"2019-10-24 09:30:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(mean(df(\"working_hour\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(mean(\"working_hour\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(mean['working_hour']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupBy('username').agg({'idle_time': 'mean'}).show()\n",
    "import datetime\n",
    "from pyspark.sql.functions import col, lit, avg \n",
    "new_working_hour = []\n",
    "converted_seconds_sum = 0\n",
    "for row in df.collect():\n",
    "    date_time = datetime.datetime.strptime(row['idle_time'], \"%Y-%m-%d %H:%M:%S\")\n",
    "    converted_seconds = date_time.hour * 3600 + date_time.minute *60 + date_time.second\n",
    "    new_working_hour.append((row['username'], converted_seconds))\n",
    "    converted_seconds_sum = converted_seconds_sum + converted_seconds\n",
    "    #print(new_working_hour) \n",
    "avg_seconds = converted_seconds_sum/88\n",
    "print(avg_seconds)\n",
    "new_column = sqlContext.createDataFrame(new_working_hour, ('username',\"seconds\"))\n",
    "#new_column.filter(new_column['seconds'] > avg_seconds).show()\n",
    "#joined_dataframe = (new_column.join(new_column, col(\"username\")==col(\"username\"),\"leftouter\").drop(\"username\"))\n",
    "\n",
    "\n",
    "new_column.filter(new_column.seconds >= avg_seconds).show()\n",
    "\n",
    "#average_object = new_column.agg(avg(col(\"seconds\"))\n",
    "#average_object = new_column.agg(avg(col(\"seconds\"))).show()\n",
    "#new_column.filter(new_column['seconds'] > ).agg(avg(col(\"seconds\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "average_object = df.agg(avg(col(\"idle_time\")))\n",
    "highest_idle_time = df.filter(df['idle_time'] > average_object)\n",
    "fhighest_idle_time.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
